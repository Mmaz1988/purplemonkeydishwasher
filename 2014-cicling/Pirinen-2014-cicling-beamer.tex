\documentclass[t,12pt]{beamer}

\usepackage{fontspec}

\usepackage{xunicode}
\usepackage{xltxtra}

\usepackage{polyglossia}

\setmainfont{Liberation Serif}
\newfontfamily\devanagarifont{Lohit Nepali}

\setmainlanguage{english}
\setotherlanguages{sanskrit}


\usepackage{graphicx}
\usepackage{color}
\usepackage{url}
\usepackage{textpos}
\usepackage{xspace}
\usepackage{array}
\usepackage[normalem]{ulem}

\newcommand\misspelt{\bgroup\markoverwith
{\textcolor{red}{\lower3.5pt\hbox{\sixly \char58}}}\ULon}
\DeclareRobustCommand{\fuuuuu}[1]{\texorpdfstring{\misspelt{#1}}{#1}}


\graphicspath{{./fig/}}

% theme options: hy/ml/hum, rovio/sinetti, hiit
% default: hy,rovio

%\usetheme[hy]{HY}
%\usetheme[hy,sinetti]{HY}
\usetheme[hum,rovio]{HY}
%\usetheme[ml,rovio]{HY}
%\usetheme[ml,rovio,hiit]{HY}


\title{State-of-the-art in Weighted Finite-State Spell-Checking\\
\scriptsize{CICLING 2014, \devanagarifont{काठमाडौं}}}

\author{\fuuuuu{Tommi A Pirinen} \and Krister Lindén
\scriptsize \guilsinglleft{}firstname.lastname@helsinki.fi\guilsinglright{}} 
\institute{University of Helsinki\\Department of Modern Languages}
\date{\today}

\begin{document}

\selectlanguage{english}

\HyTitle
%\maketitle

\begin{frame}
    \frametitle{Outline}
    \tableofcontents
\end{frame}


\AtBeginSection[]
{
  \begin{frame}<beamer>
    \frametitle{Outline}
    \tableofcontents[currentsection]
  \end{frame}
}

\section{Introduction}

       
\begin{frame}
    \frametitle{Spell-Checking}
    \begin{itemize}
        \item Spell-Checking is everywhere: browsers, office software, mobile
            phones, \ldots
        \item Three tasks: for each word \begin{enumerate}
                \item detect if word is correctly written / how likely the
                    written word is what was meant (language modelling
                    for error detection)
                \item if not, what modifications can be made to find more
                    likely correct word (error modelling)
                \item rank corrections in order of likelihood
                    (language modelling for error correction)
            \end{enumerate}
        \item Example: 1) cta 2) swap adjacent letters 3) Did you mean: cat?
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Spell-Checking and State-of-the-Art}
    \begin{itemize}
        \item State of the art as we know it: software: hunspell (limited
            edit distance, no statistics) commercial products (frequency word-form lists?); science: correct, bayspell, etc. (statistics, linguistic analysis)
        grammar checkers: LanguageTool, ... (context-based \(n\) gram
            models, programmatic rules)
        \item Three tests to prove: \begin{enumerate}
                \item coverage of the dictionary
                \item accuracy of corrections
                \item speed of spelling and correcting
            \end{enumerate}
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Test Data and Methods}
    \begin{itemize}
        \item All tests were tested on Wikipedia data, it is the only free
            open source corpus source for many languages
        \item The size and quality of Wikipedias varies: English data is
            huge, Finnish is large-ish and Greenlandic tiny and low-quality
            (written by non-native students)

        \item We scraped some spelling error with right corrections using
            Wikipedia change logs
    \end{itemize}
\end{frame}

\begin{frame}[label=links]
    \frametitle{Reproducible and usable spell-checking}
    \begin{itemize}
        \item Get it for LibreOffice (Mac OS X and Windows):
            \url{http://divvun.no/libreofficeoxt.html}
        \item Compile it for LibreOffice, enchant (works on nearly all
            reasonable Linux software):
            \url{https://sourceforge.net/projects/hfst/files/spell-transducers/}
        \item Reproduce experiments, try it out for your language, \ldots:
            \url{https://github.com/flammie/purplemonkeydishwasher/tree/master/2014-cicling}
    \end{itemize}
\end{frame}

\section{Tests for the State-of-the-Art}

\begin{frame}
    \frametitle{Coverage}
    \begin{itemize}
        \item Finite-state methods are well established in morphological
            dictionary writing / language modelling (cf. \emph{Two-level
            morphology} Koskenniemi (1983); \emph{Finite-State Morphology}
            Karttunen and Beesley (2003), \ldots)
        \item Naive coverage tests presented in the paper shows greatly
            larger coverage for Finnish
        \item Greenlandic has not been show with non-finite state methods
            beyond some 25 \% coverage (according to my colleagues at
            \url{oqaaserpassualeriffik.org})
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Coverage Results}
    Naive coverage = proportion of tokens with > 0 analyses
    \begin{tabular}{l|rrrrrrr}
        Model & English aspell & English FSA & Finnish FSA & North Sámi Hunspell & North Sámi FSA & Greenlandic FSA \\
    Coverage & 22.7 & 80.1 & 64.8 & 34.4 & 48.5 & 25.3 \\
    \end{tabular}
    The naive coverage figures give some idea of the starting point for
    spelling corrector and the corpus data quality.
\end{frame}

\begin{frame}
    \frametitle{Accuracy}
    \begin{itemize}
        \item Tested on the wikipedia's errors as logged by real users with
            some conventional comment
        \item Only solvable errors (target word-form in dictionary)
        \item Improvement in 1st guess correct and cumulative corrections
            for all langauges
        \item Likely because of addition of word form frequency statistics
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Accuracy Results}
    Quality = Proportion of correct suggestions at given position
    \begin{tabular}{l|rr}
        Language Model & $1^{st}$ & $2^{nd}$ \\
        English aspell &55.7 & 5.7 \\
        English Hunspell &59.3 & 5.8 \\
        English WFSA &66.7 & 7.0 \\
 \hline 
 Finnish aspell & 21.1 & 5.8 \\ 
 Finnish WFSA  & 54.8 & 19.0 \\
\end{tabular}
Less resourced languages' scarce error data is further discussed in the paper
\end{frame}

\begin{frame}
    \frametitle{Speed}
    \begin{itemize}
        \item Easy measure, fed wikipedia data to command line spell-checkers
            and measured throughput
        \item Two test sets: all data (real world speed) and only known
            misspellings (correction speed)
        \item Beats Hunspell on all measures, aspell is still fastest though
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Speed Results}
    Speed = tokens processed per second (raw data), Memory = peak resident stack
    size
    \begin{tabular}{l|rr}
        Language Model & Words per Second & Memory in MB\\
        \hline
       English Hunspell & 74 & 7.5 \\
       English aspell & 20,000 & 1.3 \\
       English WFSA & 5,721 & 7.0 \\
        \hline
        North Saami Hunspell & 3 & 151.0 \\
       North Saami WFSA & 5,025 & 31.4 \\
        \hline
        Greenlandic WFSA & 85 & 300.4 \\
    \end{tabular}
\end{frame}

\begin{frame}
    \frametitle{Conclusion}
    \begin{itemize}
        \item Our WFST spell-checking beats de facto standard open source
            systems on speed, accuracy and coverage
        \item It is a speed to quality trade-off, this experiment shows we can
            tune the parameters to optimise all aspects
        \item We have available usable spell-checkers for numerous languages
        (\hyperlink{links}{\beamergotobutton{Links}})
            and can generate more given a corpus or dictionary data in some
            palatable format
    \end{itemize}
\end{frame}

\section{The last slide section}

\begin{frame}
    \frametitle{Thanks kiitos \devanagarifont{ धेरै धेरै धन्यबाद}}
    Questions?
\end{frame}

\end{document}
% vim: set spell:
