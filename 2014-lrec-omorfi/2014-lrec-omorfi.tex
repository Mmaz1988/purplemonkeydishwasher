\documentclass[a5paper]{article}

\usepackage{amssymb}
\usepackage{polyglossia}

\usepackage{fontspec}
\usepackage{xunicode}
\usepackage{xltxtra}

\usepackage{url}
\usepackage{hyperref}
\usepackage[obeyDraft]{todonotes}

\usepackage{graphicx}
\usepackage{geometry}

\setmainfont[Mapping=tex-text]{Liberation Serif}

\title{Collecting, Extending, Verifying and Regression Testing Lexical Data through
Use of Large Corpora---A Case Study in Management of Finnish Lexicon}

\author{Tommi A Pirinen \and Juha Kuokkala \and \ldots}

\date{\today}

\begin{document}

\maketitle

\begin{abstract}
    In this article we demonstrate the use of large coverage varied real text
    corpora for four different purposes: first to collect new lexical data, i.e.
    word-forms, classifications and other features, second to extend existing
    lexical data, third to verify lexical data collected from various sources
    and finally to regression test the full system developed using the lexical
    data. In our experiment we take a free and open source Finnish morphological
    analyser, we verify some existing features that are morphological (i.e.,
    visible in the word-form) as well as  extend and verify some features that
    are syntactic-semantic (i.e., visible in distribution and context). We
    also demonstrate that the resulting morphological and surface-syntactic
    statistics extracted in the process can be readily used as naive statistical
    language models.
\end{abstract}

\section{Introduction}
\label{sec:introduction}

For a mature computational language description, harvesting and maintaining the
masses of lexical data is one of the main tasks done all the time. In a
modern environments, this task is no longer carried on by one computational
linguist expert. Often they are harvested from various crowd-sourced dictionary
development environments, such as Wiktionary\footnote{} or O\-mega\-wi\-ki\footnote{},
and while ideally they need to be verified by competent language speaker before
integrating into system, often the task is time consuming and prone to mistakes,
so providing rigorous test sets by use of extensible corpora is crucial. Another
aspect of lexical data harvesting that often comes into focus is when extending
the use of an computational linguistic description into new applications, it
is invariably necessary to create new classifications for word-forms. For
example the Finnish morphology that we use has been adapted to Finnish-English
machine translation, which needed among others the gender of human referent
nominals in order to get personal pronouns right, another project adapted the
analyser to named entity recognition task, which in turn needed great quantities
of new proper nouns added to the dictionary and classified by semantic means.

The concept of using corpora as means of harvesting new data is not new in
itself, in fact probably most linguistic projects that make use of
lexicographical data will have at some point used corpora to extract new words
and features from, e.g., for extraction part alone, LREC held in 2012 had at
least 5 papers. What we provide here is a software engineering oriented view on
using corpora as properly integrated test unit on all phases of lexicon
development for continuous and semi-automated maintenance of the lexical data
instead of single updates of partial data.

\section{Methods}

The methods for creating statistics from corpus data we use in this projects
currently only depend on python data structures having access to the corpus
data, the tokens it forms and sets of analyses the corpus processing system
attaches for each token. In our case we have a python interface to FST-based
corpus processing, which provides unambiguous left-to-right longest
tokenisations of the text, and ambiguous morphological analyses along with some
classification information per word-form. From this we gather statistical
distributions, such as specific word-form analyses per lemma, and word-forms or
analyses at specific contextual positions. Each of the types of information
gathered in this manner is based on linguistic knowledge of existing
classifications, mainly encoded in the official grammar~\cite{visk}, and should
therefore form an ideal test for collecting, verifying and testing the
classifications. E.g., a \emph{morphological adjective}\footnote{Word
`adjective' is somewhat problematically defined loosely in terms of morphology,
syntax and semantics together, which makes classification often troublesome for
computational methods.} is recognised by the existence of comparative forms,
and the lack of those forms will be a good clue of misclassification. On the
other hand \emph{syntactic adjective} is defined by having an agreeing nominal
on right context or predicative verb in the left context. Ideally these two
classes would of course be disjoint to begin with, to make classification more
systematic, since they do not form a proper homogeneous uniform class.

\section{Data}

For experimentation we have used a mature language description of
Finnish~\cite{pirinen2011modularisation} that consists some 400,000 lexemes and
a few existing classifications, such as part-of-speech classes, inflectional
paradigms, and proper noun classes. The lexical data comes from number of
projects varying from institute of languages in Finland's official dictionary
and academic projects to fully crowd-sourced projects like Wiktionary. To test
out that the classifications match the expectations we have used three large
and well-established free and open source corpora: Wikipedia~\footnote{},
Project Gutenberg~\footnote{} and texts of European parliament from JRC
Acquis~\footnote{}. 

\section{Evaluation}

To evaluate the scheme we have randomly sampled the statistics that give the
strongest evidence (multiple matches with over 95~\% of agreement or less than 
5~\% in case of negative matches) of either
disproving the current class or extending the classification with new
information, and evaluated them using linguistic expertise and the specific
contexts. The results are given in the table~\ref{table:results}.

\section{Discussion}

In previous work the corpora have been used for single time extension of the
lexical data~\cite{} or coverage based maintenance of computational linguistic
description~\cite{}. We have presented a sustainable way of integrating corpora
as part of the development work-flow to extend, verify and maintain the lexical
data and language description clean and free of errors.

\subsection{Error Analysis}

When looking at some of the tests that fail to give good results, we notice
that even with as large corpora as we use, the lack of data may leave existing
linguistic phenomena non-existing. For example both the data in our corpora and
official grammar classify `\emph{kielitieteellinen}' (linguistic) as an
non-comparing adjective, yet a simple Google search yields a number of real
world results, that are grammatical, such as: ``\emph{Torstain haastavampaan
    settiin lukeutuu sit se avoin \textbf{kielitieteellisempi} kurssi, jossa
valtaosa opiskelijoista on
japanilaisia}''\footnote{\url{http://7830km.blogspot.fi/2013/04/mulla-kauas-paluulippu-on.html}}
(\ldots open \textbf{more linguistic} course \ldots) and ``\emph{Tosin aihe on
\textbf{kielitieteellisempi} kuin muistaakseni mik채채n kielitiederyhm채채n viime
kuukausina tulleista artikkelista,}''
\footnote{\url{news:oiiup4p6hj.fsf@beta.hut.fi}} (\ldots is \textbf{more
linguistic} than any other \ldots). For this reason there needs to be methods
for an expert to override and blacklist / whitelist the results as necessary.

\subsection{Future Work}

In this experiment we worked with ambiguous morphological analyses and simple
positional rules only capable of scanning specific relative
positions. For many of the real linguistic definitions, it would be interesting
to have better analyses and word-to-word relations available, e.g., such that
dependency tree banks have.

\section{Conclusion}

In this article we applied large corpora-based extraction, verification and
testing for Finnish language description. Results show that even with quite
tight thresholds we are able to extract good new data and clean up existing
data with accuracy of nnn~\%.

\bibliographystyle{unsrt}
\bibliography{lrec2014}

\end{document}
% vim: set spell:
