\documentclass[a4paper,12pt]{article}

\usepackage{fontspec}
\usepackage{xunicode}
\usepackage{xltxtra}

\usepackage{url}
\usepackage{hyperref}

\usepackage[margin=3cm]{geometry}

\usepackage{natbib}

\linespread{1.3}

\setmainfont{Times New Roman}

\title{Omorfi–Newest Computational Morphological Analysis of Finnish}

\iffalse
\author{Tommi A Pirinen}
\fi

\begin{document}

\maketitle

\begin{abstract}

    This squib describes a contemporary system for computational analysis of
    morphology of Finnish word-forms. We show few key differences and new
    ideas compared to popular existing systems: Firstly extended classification
    that has been needed to
    accommodate computational semi-automatic classification of new words and
    finetune the inflectiona variants, and to systematically go through the
    synchronic variations in morphophonology of Finnish on character level.
    Secondly we describe the recent developments in field of statistical
    computational linguistics and show how we have adapted the findings in
    the field to our traditional rule-based approach of Finnish morphology,
    The system presented in the paper is considered to be of general use. 
    Thirdly, our system is based fully on free and open source systems and
    approaches, to this end we show the use of crowd-sourced dictionary 
    Wiktionary as a source of lexical data. To
    evaluate the system we have analysed large text corpora on the system
    and verified that only 1~\% of the word-forms remains unknown to the system.
    We have also made rudimentary quality and speed 
    comparisons against results of the systems currently in use.

\end{abstract}

\section{Introduction}

Computational morphological analysis is a central component for most of the
computational applications of linguistic analysis. The morphological analysis
for Finnish language was first described some 30 years ago~\cite{}. The
aim of this paper is to examine the differences of our current approach to
traditional systems that are used for the task and to highlight some of the new
developments that are relevant to our system. The new developments that we
discuss are mainly in line with the recent trends in the field of computational
linguistics. In the recent years, there has been sharply rising interest in the
statistical methods for computational linguistics. However, morphologically
complex language like Finnish does not lend itself as easily for statistical
treatment, so we try to bring into focus the modifications to the basic
statistical approaches that we have applied to have them working for Finnish
morphological analysis. 

One of the main goals of this paper is to act as the central scientific
documentation of our current morphological analyser, and we have made an
attempt to highlight the long-term design goals of the system instead of
transitional and volatile features of a fast-moving computer software that is
developed by a base of open source and language enthusiasts.

In computational linguistics, the beginning of 2000's has been
largely time for statistical language models and engineering. It is commonly
argued that statistical models are not as easily suitable for morphologically
complex languages like Finnish as they are for e.g. English. Our system is
based on the same assumption, and the core of the system is similar rule-based
system as described in earlier research of Finnish analysis. In this article
we show how we have integrated statistical features to traditional rule-based
morphological analyser of Finnish language that has been developed
earlier in University of Helsinki~\cite{pirinen2008}. We furthermore demonstrate
a full-fledged version

Another recent development in the computational language models is the concept
of \emph{maintainability} of these computational systems, e.g.
in~\cite{maxwell}. Specifically we will show how we use the power of
\emph{crowd-sourcing} to keep up with the new words, neologisms and other rare
words missing from dictionary. In particular we study the use of the popular
online dictionary Wiktionary as a source of additional lexical data. The
crowd-sourcing as well as few newer morphological phenomena in the language
have implications to lexicographical structure of the data as well, so we try
to describe in this article some of the newest findings based on the word data
we have added to lexical resources of our systems. While morphology of language
is quite resistant to change, variations such as quantitative consonant
gradation of the bleh stops have required new additions to existing
classifications. Furthermore we have re-analysed the generalisations of old
lexicographical classifications and noted that resulting system is more
favorable for computational systems as well as human classifiers to make
educated guesses when classifying unknown words–as well as verifying
classifications of existing lexical data.

The basic framework of the computational system we present here is largely
unchanged from the one introduced in~\cite{koskenniemi1983twolevel}. 
The finite-state automata remain the state-of-the-art for morphological analysis
of morphologically complex languages to date. The main
technological difference is that we are now using weighted finite-state 
automata~\cite{openfst}, which practically means that we have capability to
express statistics or preference relations in our morphological dictionaries.
In this article we show how we have used existing methods and findings with
our Finnish morphological analyser.

On the linguistic side, one of the central design decisions in omorfi is to
be a system that captures the concensus of \emph{linguistic knowledge}. This
means that the system is built to create analyses that have been accepted by
linguistic community. Specifically we try to avoid making analysis decisions
based on ad hoc needs of certain types of computational linguistics software.

To summarise, this article tries to give an overview of the Finnish analyser,
collecting together the past years of experiments that have gotten into the
working system and contrasting them with other systems that have been or are
in practice use for Finnish computational morphologies.

The paper is organised as follows: In section~\ref{sec:background}, we go
through the basic concepts of Finnish morphology, modern finite-state
technology and the management of lexicographical data that is relatively
central to the new system. 

\section{Backgrounds}

Finnish morphology is well understood and documented, e.g. in \cite{,,} and
most recently in \cite{visk}. This is important to note, since we believe that
the point of computational morphological analyser is primarily to capture
contemporary linguistic knowledge about word-forms as accurately as possible.
Therefore we have made an attempt to follow the descriptions of the newest
research on words in \cite{visk}[chapter 1].

The features of Finnish morphophonology that are directly relevant to this
topic are stem variations, vowel harmony, and otherwise mostly concatenative
morphotactics. These are the only aspects of Finnish morphophonology that
determine the lexicographical classification of Finnish words for means of this
computational implementation. 

There have been numerous implementations of Finnish morphological analysis
along the years. The most popular ones can be dated back to 1980's,
including~\cite{koskenniemi1983twolevel}, which could be seen as the closest
technological relative of our implementation, and among the more influential
works in the field of computational morphology. Other such work along the years
include~\cite{holman1988finnmorf}.  More recent works have showed e.g. a fully
statistical approach for approximating a morphological segmentation of
Finnish~\cite{creutz2005unsupervised}.

In~\cite{ranta2008predictable}, Ranta presents a morphological analysis of
Finnish based on \emph{smart paradigm} system. The treatment of Finnish
lexicography in the smart paradigm system is useful reference for our work,
since it maintains similar differences to contemporary dictionaries and other
analysers as our system. 

\begin{figure}
    \begin{scriptsize}
\begin{verbatim}
kaikki  [WORD_ID=kaikki][POS=PRONOUN][SUBCAT=QUANTOR][NUM=SG][CASE=NOM]

ihmiset [WORD_ID=ihminen][POS=NOUN][NUM=PL][CASE=NOM]

syntyvät        [WORD_ID=syntyä][POS=VERB][VOICE=ACT][DRV=VA][PCP=VA][NUM=PL][CASE=NOM]
syntyvät        [WORD_ID=syntyä][POS=VERB][VOICE=ACT][MOOD=INDV][TENSE=PRESENT][PERS=PL3]

vapaina [WORD_ID=vapaa][POS=ADJECTIVE][NUM=PL][CASE=ESS]
vapaina [WORD_ID=vapaa][POS=NOUN][NUM=PL][CASE=ESS]

ja      [WORD_ID=ja][POS=PARTICLE][SUBCAT=CONJUNCTION]

tasavertaisina  [WORD_ID=tasavertainen][POS=ADJECTIVE][NUM=PL][CASE=ESS]
tasavertaisina  [WORD_ID=tasa][POS=NOUN][NUM=SG][CASE=NOM][GUESS=COMPOUND][WORD_ID=vertainen][POS=ADJECTIVE][NUM=PL][CASE=ESS]
tasavertaisina  [WORD_ID=tasa][POS=NOUN][NUM=SG][CASE=NOM][GUESS=COMPOUND][WORD_ID=vertainen][POS=NOUN][NUM=PL][CASE=ESS]

arvoltaan       [WORD_ID=arvo][POS=NOUN][NUM=SG][CASE=ABL][POSS=PL3]
arvoltaan       [WORD_ID=arvo][POS=NOUN][NUM=SG][CASE=ABL][POSS=SG3]

ja      [WORD_ID=ja][POS=PARTICLE][SUBCAT=CONJUNCTION]

oikeuksiltaan   [WORD_ID=oikeus][POS=NOUN][NUM=PL][CASE=ABL][POSS=PL3]
oikeuksiltaan   [WORD_ID=oikeus][POS=NOUN][NUM=PL][CASE=ABL][POSS=SG3]

.       [WORD_ID=.][SUBCAT=PUNCTUATION][BOUNDARY=SENTENCE]
\end{verbatim}
    \end{scriptsize}
    \caption{Example of omorfi output in analysis mode with the default
        long analysis style \label{fig:output}}
\end{figure}


\section{Data}

One of the main building blocks for rule based analysis of morphology is
lexicographical data. In order to correctly inflect a word, a root and some
classification to determine inflection is needed. Without classification, it is
only possible to guess the inflectional patterns of the word. For most Finnish
words, guessing a correct pattern is quite possible, but for purposes where
high precision is required, such as spell-checking, a manually verified lexicon
is necessary. Also, the task of classification is only needed once per word,
and does not necessarily require expert skills beyond native-like language
understanding.

The requirement for large amounts of lexicographical data is very apparent in
applications like spell-checking that require knowledge of how good a word-form
really is. For example for compound words---a potentially infinite class of
words in Finnish---a compound that is known to exist and has been attested in
a number of texts is very much a better word than a compound that can be made
up by morpholegal combination of nominals' forms.

The sources for lexicographical data for Finnish are many. The most traditional
is the dictionary maintained by Research institute of languages in Finland. For
this, the lexicographical data of the dictionary (Nykysuomen
sanalista\footnote{\url{http://kaino.kotus.fi/sanat/nykysuomi}}) has been
available under free software licence since 2007, and it is the original base
of our analyser. This data consists of some 90,000 word-forms. The
classification uses 80 numeric classes, which could freely combine with 14
alphabetic classes for the stem consonant gradation.  This means theoretically
1,120 classes, though not all combinations are possible or used. On top of that
there are few words that have multiple classes, or some that do not fit into
classification and the exceptions are defined in the prose of the
dictionary---all in all, not an ideal classification for computational
treatment. Furthermore, the background of this classification scheme were in
removing some classes from the previous one by making phonological
generalisations, such as grouping all simplifying diphthong stems under one
class, on the other hand, some classes only differ from each other by perceived
popularity of one allomorph---and neither of these classification logics has
been carried out thoroughly and systematically.

The data on official dictionary is relatively conservative and does not update
often, so it has been necessary to seek other sources of lexical data for number
of classes of words that are important in practical applications, like
neologisms, jargon, proper nouns and so forth. The first source of lexical data
we attained from the internet is a free open source user-built database named
Joukahainen\footnote{\url{http://joukahainen}}. Their database uses another
classification scheme, \ldots

Another source of lexical data we are using is crowd-sourcing, in this case the
popular Wiktionary project. Wiktionary is dictionary that is built on Wikipedia
style open for everyone editing. This results that the data quality fluctuates
quite a bit between the lexicographical entries, and it needs to be verified
more carefully. The classification of Wiktionary words varies between the
official dictionary classification to none to plain bogus classes, which happens
because Wiktionary does not restrict anyhow how the data can be inputted; users
can basically write anything in place of the classification as they see fit.

There is a fourth source of data that is commonly used, that is expert
classification at University of Helsinki, done in project basis to collect
new sets of data or to verify the data from above sources as well as data
collected by semi-automatic harvesting methods. For the needs of
these projects, we have devised a new classification, as well as computational
methods to help the workers to classify and verify the data.

The full lexical data used in the analyser consists of 396,673 classified
lexemes, the classification is roughly summarised by the classes and origin in
table~\ref{table:lexical}. The columns are the lexical sources used, in order
\emph{Nykysuomen sanalista} by KOTUS (RILF), \emph{Joukahainen}, 
\emph{Wiktionary}, terms harvested in various research project in University of
Helsinki, and lastly total sum. The rows represent coarse morphological
classification that is based on morphological features only (i.e., inflection,
not considering syntax or semantics), however, proper nouns are separated into
their own class. Notable of the others class is, that the dictionaries for
adverbs, adpositions and such words with defective paradigms have one entry per
inflectional ending, and as such they all count as non-inflecting.

\begin{table}
  \centering
    \begin{tabular}{|l|r|r|r|r||r|}
        \hline
        \bf Database: & Kotus & Joukahainen & Wiktionary & HY & \bf Total \\
        \bf Class   & & & & & \\
        \hline
        Adjectives     & 10,537 & 652 & 59 & 6,368 & 17,616 \\
        Nouns          & 67,608 & 2,945 & 1,133 & 1,589 & 73,275\\
        (Proper nouns) & 20 & 5,394 & 70 & 262,330 & 267,814\\
        Verbs          & 9,685 & 476 & 12 & 499 & 10,672\\
        Others         & 6620 & 5 & 12 & 25,536 & 32,173 \\
        \hline
        \bf Total      & 94,290 & 9,472 & 1,286 & 296,322 & 396,637 \\
        \hline
    \end{tabular}
  \caption{Lexical data used in the analyser
  \label{table:lexical}}
\end{table}

\section{Methods}

The system presented uses well-established techniques, such as
finite state morphology~\cite{beesley2003finite}. In this section we
describe specific

\subsection{Implementation of the Analyser}

The core computational methodology for the implementation of the analyser is
finite-state technology, introduced
in~\cite{koskenniemi1983twolevel,beesley2003finite}. On top of that we
have applied recent extensions from the research of finite-state morphology,
such as weighted finite-state methods~\cite{openfst,hfst2012}. This brings the
traditional rule-based language analyser towards the statistical language
analysers that are widely popular in handling of morphologically less
complex languages, e.g. for English virtually all systems currently in use
are statistical.

A naive way to apply statistical methods for morphological analysis is
straight-forward; to get the likelihood of word-form $P(w)$ as a surface form
$w$, we calculate the amount of word-forms $f(w)$in a corpus and divide it by
the number of word-forms in the whole corpus $CS$. This is shown in formula:

$$
P(w) = \frac{f(w)}{CS}
$$

For a morphologically complex language with relatively little corpora, the
frequency of most of the word-forms is $0$. To handle this gracefully, we need
to estimate the probability of unseen words and offset a part of the
probability mass among them. A basic schoolbook approach to this is
\emph{additive discounting}, where we simply assume that all unseen words have
appeared in the corpus $\alpha$ times, and we increase the corpus size by
$\alpha$ per each type $T$ in the corpus. This is shown in formula:

$$
P(\hat w) = \frac{f(w) + \alpha}{CS + T \times \alpha}
$$

Another consideration that we used from recent research
findings~\cite{pirinen2009weighting} is the estimation of the compound words by
their parts, this means that given unseen compound \emph{banaaniovi}, the
estimated likelihood is $P(\mathrm{banaani}) \times P(\mathrm{ovi})$, rather
than $P(\mathrm{\hat banaaniovi})$. One of the non-apparent results of such
training is that in case of ambiguous compounds, the analyser will
systematically prefer the ones with least words.

\subsection{Classification and Its Use}

The lexical data that is used in the analyser comes from variety of sources,
with different quality, classification schemes (or lack of thereof) and \ldots.
To maintain the data we have rethought the classification scheme by
systematically analysing the word-forms of each paradigm on character level such
that for each stem variation and each suffix, the word is considered to be in
the same class iff each character of the each stem's corresponding varying part
and each character in each suffix allomorph variant is the same. 

To contrast our classification with the existing classification we get, for
example, two separate classes for each class by the difference in vowel
harmony: this is evident because for inessive suffix \emph{ssä} and \emph{ssa}
are not the same on the character level. Similarly we get four classes instead
of one for the non-alternating nominal stems since the singular illatives
\emph{on}, \emph{un}, \emph{yn}, \emph{ön} are not the same on character level.
Since there is a number of minor details in Finnish morphophonology that
results combinatorically in quite many classes, we provide the whole table with
mappings to existing other systems in our wiki
page\footnote{\url{https://code.google.com/p/omorfi/wiki/InflectionClassTables}}.



\section{Evaluations}

In this section we present the evaluation of our system as a full-fledged
morphological, and we also evaluate the lexicographical system we use for
the classification of new word-forms. To show how our new lexicographical
classification improves from the baseline of the contemporary dictionary
classification, we show a run of word-forms found in number of resources that
old dictionary deemed non-existing or rare.

\subsection{Dictionary Coverage}

First we measure the naive coverage for the systems where it is possible to
measure naive coverage. This tells how many of the word-forms in the material
are out-of-vocabulary items. The naive coverage is formally defined as
$\mathrm{Coverage} = \frac{\mathrm{Analysed}}{\mathrm{Corpus size}}$. The
results are presented in table~\ref{table:coverage}. 

\begin{table}
    \centering
    \begin{tabular}{|l|r|r|}
        \hline
        \bf System: & Omorfi & FINTWOL \\
        \hline
        \bf Corpus & & \\
        \hline
        Gutenberg & 98.3~\% & 93.0~\%   \\
        Wikipedia & 98.4~\% & 92.7~\% \\
        Europarl  & 99.3~\% & 93.6~\% \\
        \hline
    \end{tabular}
    \caption{Naive coverages when analysing common corpora
    \label{table:coverage}}
\end{table}

\subsection{Analysis Recall Compared to Old Systems}

The correctness of analysis was measured using the analyses of Finnish text
collection corpora. From there we picked the \emph{Helsingin sanomat} corpus
from the year 1995. In context of morphological analysis, recall is measured as
a proportion of correct results in all results, or formally $\mathrm{Recall} =
\frac{\mathrm{Correct}}{\mathrm{Correct} + \mathrm{Missing}}$. In 
table~\ref{table:quality} we show the results for our system with random
selection of the results, and then with the selection based on unigram 
probabilities and estimated analysis weights. The reference corpus is based on
other system's output so we assume its results are around 100~\% and have not
shown it in the table.

\begin{table}
    \centering
    \begin{tabular}{|l|r|r|r|}
        \hline
        \bf Measure & Recall at 1 & Recall at 1---5 & Recall 1---$\infty$  \\
        \hline
        \bf Syatem & & & \\
        \hline
        Baseline & 26.3~\% & 76.7~\% & 90.5~\%\\
        With weights & 27.7~\% & 79.8~\% & 90.5~\%\\
        \hline
    \end{tabular}
    \caption{Quality of the analyser measured as equality to results of
        another analyser \label{table:quality}}
\end{table}

\subsection{Processing Speed}

To measure the processing speed we simply measured analysis time of 10,000,000
first word-forms in Wikipedia corpus over five runs and averaged the results
from that. The results in table~\ref{table:speed} are given in word-forms per
second terms.

\begin{table}
    \centering
    \begin{tabular}{|l|r|r|r|r|}
        \hline
        \bf System & Omorfi & fintwol & textmorfo & fifdg \\
        \hline
        \bf Corpus &        &         &           & \\
        \hline
        Wikipedia & 56,179  & 14,705  & 2,010 & 2,584 \\
        \hline
    \end{tabular}
    \caption{Quality of the analyser measured as equality to results of
        another analyser \label{table:speed}}
\end{table}

\section{Discussion}

Morphological analysis of Finnish by computational methods and finite-state
automata is a 30 year old topic. In this paper we attempt to study the
similarities and differences that our current system has to those developed in
the years between. One feature that is new compared to most of the systems, is
the possibility of statistical and similar values. The result of this is very a
baseline morphological disambiguation, which can be usable for information
extraction and similar applications where the accuracy requirement for top
results is not so crucial. This should also be usable as baseline for systems
that perform morphological disambiguation based on full syntactic analysis,
like constraint or dependency grammars~\cite{karlsson}.

There are a couple of reasons for meticulous re-classification of paradigms
we did in the system. One is that by systematically resorting to synchronic
character level knowledge, we could get the most simple naive morphological
description that lends itself to automatic classification of out of vocabulary
words. For example, the longest suffix classification works quite well in
guessing the paradigms, however, if you are using the old classification
scheme, trying to find evidence that word belongs to class 1 by the fact that
we try to find illatives of form \emph{Vn} or inessives of form \emph{ssA} is
slightly harder task than finding the wordforms with suffix exactly e.g.
\emph{on} and \emph{ssa}. To that aspect, the system is not useful only
for guessing, as the lexical data comes from various sources, including
freely editable dictionary, we can also use the automatic classification
schemes to ensure that the word data coming from such sources is classified to
our expectations.

The measurements of precision and recall we use in the evaluation section are
based on a ``gold standard'' that is merely a result of another automatic
analyser, not necessarily a representative of correctly analysed Finnish. For
this effect, it is better to read the precision and recall scores as 
\emph{faithfulness} scores of our system being a re-implementation of the
reference system.

It is also noteworthy that the speed of the systems is not directly comparable
for \texttt{textmorfo} and \texttt{fi-fdg}, which perform full morphosyntactic
analysis, whereas omorfi only does isolated morphological analysis. It is
possible to extend omorfi with some syntactic analysis capabilities using
Karlsson's Finnish CG~\cite{} available as free/open source implementation
in University of Tromsa's open source computational linguistics 
repository~\footnote{\url{http://giellatekno.uit.no}}. The modifications
required to match the analyses with the system's expectations are minimal.

\section{Conclusion}

In this article we set out to show some features of the newest edition of our
Finnish morphological analyser. We have showed that it gives reasonably good
results for basic analysis tasks with much higher coverage, precision and recall
than other systems currently in use. We studied the usefulness of systematic
re-classification of Finnish inflectional paradigms based on synchronic
orthographical evidence, and found that it provides some benefits for tasks
like automatic classification and verification of new lexical data.

% apalike with underscores???
\bibliographystyle{apalike}
\bibliography{omorfi2013}

\end{document}
% vim: set spell:
